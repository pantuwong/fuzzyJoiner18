-Lay out a series of milestones
	-impliment a naive version of the algorythim.
		-use wikipedia to get people and organization names
		-100,000 companies and 
		-column 1 url
		-column 2-n variants of that person or company name
		-see if they are part of the actuall name (clean data)
			-start with postgresql
		-if any
-Download postgresql (get 96).
-write data cleaner in python
-implement basic 
-data.gov
	-free open data
-possibly group by bucket to reduce size of large table 

-work on cleansing
-remove titles
-add nicknames (before blocking)
-contract abreviations for companies (before blocking)
-think about fetures 
	-word frequency
	-two names are substitutes
		-auto vs. automobile
		-holdings corperation
-first deal punctuation
-block by slamming things together
-think about less deteriministic mixes
-remove by frequency count in blocking
	-binary search

-clean up the code
-look up some nlps for udfs (nltk)
-misses from blocking
-throw out big buckets
-open corperate
-try to understand why I am throwing out so many names